\section{Large Multimodal Models (MLLM)}
1. \textbf{Tokenizer:} Converts input sequences into discrete tokens. \\
2. \textbf{Next Token Prediction:} \\
   a. Causal mask applied to self-attention. \\
   b. Classifier predicts the next token from hidden states of previous tokens. \\
3. \textbf{Model Training:} \\
   a. Pretraining. \\
   b. Instruction tuning. \\
   c. Preference alignment. \\
